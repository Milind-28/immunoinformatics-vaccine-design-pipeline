{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c972d53d-16f7-44f4-8917-87564d36d494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting biopython\n",
      "  Using cached biopython-1.85-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from biopython) (1.26.4)\n",
      "Using cached biopython-1.85-cp312-cp312-win_amd64.whl (2.8 MB)\n",
      "Installing collected packages: biopython\n",
      "Successfully installed biopython-1.85\n"
     ]
    }
   ],
   "source": [
    "!pip install biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17866afd-3ffb-4308-9d46-69570c8b695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio import Entrez\n",
    "from http.client import IncompleteRead\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm  # Progress bar\n",
    "\n",
    "# Set your email and API key\n",
    "Entrez.email = \"milindshri28@gmail.com\"  # Replace with your email\n",
    "Entrez.api_key = \"61a0177ec4272f5e476e8be374a500c38308\"   \n",
    "\n",
    "def safe_efetch(db, id, rettype, retmode, max_retries=3):\n",
    "    \"\"\"Retries efetch in case of connection failure.\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            handle = Entrez.efetch(db=db, id=id, rettype=rettype, retmode=retmode)\n",
    "            return Entrez.read(handle)\n",
    "        except IncompleteRead as e:\n",
    "            print(f\"IncompleteRead error: {e}. Retrying {attempt + 1}/{max_retries}...\")\n",
    "            time.sleep(5)  # Wait before retrying\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def fetch_protein_data(query, max_records=10):\n",
    "    \"\"\"\n",
    "    Fetches Accession numbers, VRL, and other metadata from the NCBI protein database.\n",
    "    \n",
    "    :param query: Search term for NCBI database\n",
    "    :param max_records: Maximum number of records to retrieve\n",
    "    :return: List of dictionaries with metadata\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Searching for '{query}' in NCBI Protein Database...\")\n",
    "        handle = Entrez.esearch(db=\"protein\", term=query, retmax=max_records)\n",
    "        record = Entrez.read(handle)\n",
    "        handle.close()\n",
    "        \n",
    "        ids = record[\"IdList\"]\n",
    "        data = []\n",
    "\n",
    "        print(f\"Fetching {len(ids)} protein records...\")\n",
    "\n",
    "        # Progress bar\n",
    "        for protein_id in tqdm(ids, desc=\"Processing\", unit=\"record\", dynamic_ncols=True):\n",
    "            time.sleep(1)  # Avoid NCBI rate limits\n",
    "            records = safe_efetch(\"protein\", protein_id, \"gb\", \"xml\")\n",
    "            if not records:\n",
    "                continue  # Skip if failed\n",
    "\n",
    "            for rec in records:\n",
    "                accession = rec.get(\"GBSeq_accession-version\", \"N/A\")\n",
    "                modification_date = rec.get(\"GBSeq_update-date\", \"N/A\")\n",
    "                description = rec.get(\"GBSeq_definition\", \"N/A\")\n",
    "                organism = rec.get(\"GBSeq_source\", \"N/A\")\n",
    "                sequence_length = rec.get(\"GBSeq_length\", \"N/A\")\n",
    "                name = rec.get(\"GBSeq_locus\", \"N/A\")\n",
    "\n",
    "                host, geolocation, date_of_collection = \"N/A\", \"N/A\", \"N/A\"\n",
    "                \n",
    "                for feature in rec.get(\"GBSeq_feature-table\", []):\n",
    "                    if feature.get(\"GBFeature_key\") == \"source\":\n",
    "                        for qualifier in feature.get(\"GBFeature_quals\", []):\n",
    "                            if qualifier[\"GBQualifier_name\"] == \"host\":\n",
    "                                host = qualifier[\"GBQualifier_value\"]\n",
    "                            elif qualifier[\"GBQualifier_name\"] == \"geo_loc_name\":\n",
    "                                geolocation = qualifier[\"GBQualifier_value\"]\n",
    "                            elif qualifier[\"GBQualifier_name\"] == \"collection_date\":\n",
    "                                date_of_collection = qualifier[\"GBQualifier_value\"]\n",
    "\n",
    "                data.append({\n",
    "                    \"Accession\": accession,\n",
    "                    \"DOM\": modification_date,\n",
    "                    \"Organism\": organism,\n",
    "                    \"Host\": host,\n",
    "                    \"Geolocation\": geolocation,\n",
    "                    \"DOC\": date_of_collection,\n",
    "                    \"Name\": description,\n",
    "                    \"Size\": sequence_length,\n",
    "                })\n",
    "        \n",
    "        print(\"✅ Fetching complete!\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7808b9ec-4a61-4535-b256-812d43907f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from NCBI...\n",
      "Searching for 'Severe fever with thrombocytopenia AND \"nucleocapsid\" ' in NCBI Protein Database...\n",
      "Fetching 5 protein records...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|████████████████████████████████████████████████████████████████████| 5/5 [00:12<00:00,  2.46s/record]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fetching complete!\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    search_query = 'Severe fever with thrombocytopenia virus AND \"nucleocapsid\" '  # Replace with your query\n",
    "    max_records_to_fetch = 5    # Adjust as needed\n",
    "    \n",
    "    print(\"Fetching data from NCBI...\")\n",
    "    nucleotide_data = fetch_protein_data(search_query, max_records = max_records_to_fetch)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cfd2b8b-6c7b-4017-bd66-be979a3f2be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file saved as 'Sup_Data.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Assuming `nucleotide_data` is a list of dictionaries\n",
    "data = nucleotide_data\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "if data:  # Check if data is not empty\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Save the DataFrame to an Excel file\n",
    "    output_file = \"Sup_Data.xlsx\"\n",
    "    df.to_excel(output_file, index=False, engine=\"openpyxl\")\n",
    "    \n",
    "    print(f\"Excel file saved as '{output_file}'\")\n",
    "else:\n",
    "    print(\"No data available to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec00ac-e137-4997-a665-86e78d004657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
